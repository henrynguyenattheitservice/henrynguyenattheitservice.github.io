[{"id":0,"href":"/posts/","title":"Blog","section":"","content":""},{"id":1,"href":"/posts/land-system/","title":"Land System","section":"Blog","content":"Disclaimer: The User Requirements Specification documentation is broken down into two parts to remove the unambiguous in the Requirements and the Specification:\nUser-requirements means the user document the requirements without any implementation intention, e.g. the user document to build a house with four windows and a door. User-specification means the user document the requirements to be implemented with specification, e.g the user document to build a house for human to live with a door specified by the manufacture and four windows specified by the manufacture. Specification imposes the implementation constraints. Here is a possible system design solution with the following user-specifications and assumptions to be validated and invalidated: Architecture is based on the TCP/UDP with IP architecture Here is a possible system design solution with the following assumptions to be validated and invalidated: Architecture is based on the Data Distributed System (DDS). Please note that I still use the word Architecture here as DDS as it is the standard and solution widely used in the defence system development. \u0026ldquo;A Distributed Data System (DDS) is a system that allows data to be exchanged among different applications or devices in a network using a publish-subscribe pattern. DDS has a standard protocol and API defined by the Object Management Group (OMG), which specifies the communication semantics and quality of service for data-centric connectivity¹³. DDS also follows the standards for data management and interchange set by the ISO/IEC JTC 1/SC 32, which aim to promote harmonization of data facilities across different domains\u0026rdquo;. RTI, Vortex and eProsima are three vendors that offer implementations of the DDS standard. RTI and Vortex are commercial vendors, while eProsima offers both commercial and open source solutions. eProsima Fast DDS (formerly known as Fast RTPS) is an open source implementation of the OMG DDS that claims to be faster and easier to use than other implementations¹. However, there may be some compatibility issues between eProsima Fast DDS and RTI Connext DDS, as they use different versions of the DDSI-RTPS protocol²³. eProsima also develops other products such as eProsima RPC for DDS, which is a remote procedure call framework based on DDS⁴. (1) DDS - eProsima. https://eprosima.com/index.php/resources-all/whitepapers/dds. (2) RTI pub/subs are not able to communicate with eProsima FastDDS pub/subs. https://community.rti.com/forum-topic/rti-pubsubs-are-not-able-communicate-eprosima-fastdds-pubsubs. (3) Compilibility of eProsima FastDDS and RTI Context DDS [10768 \u0026hellip; - GitHub. https://github.com/eProsima/Fast-DDS/issues/1809. (4) eProsima | Data Distribution Service (DDS) Community RTI Connext Users. https://community.rti.com/partners/eprosima. Source: Conversation with Bing, 11/08/2023 (1) Data Distribution Service - Wikipedia. https://en.wikipedia.org/wiki/Data_Distribution_Service. (2) What is DDS?. https://www.dds-foundation.org/what-is-dds-3/. (3) About the Data Distribution Service Specification Version 1.4. https://www.omg.org/spec/DDS/1.4/About-DDS/. (4) ISO/IEC JTC 1/SC 32 - Data management and interchange. https://www.iso.org/committee/45342.html. I have developed a Proof Of Concept to research into the embedded software development with Yocto with running Vortex DDS @ ADLINK Tech. Special thank and acknowledge the assistance to the Sale Engineer and Technical Support at ADLINK. I could not acquire the RTI DDS software @ RTI and eProsima DDS to test out the concept. In general, I would like to test out: Yocto/Openembedded OS image with the running Docker tested on the RaspberryPI and Intel Development Board (I did test out initially but unfortunately had to abandon as runing out of time) OS image running on read only file system to test out the concept where the system will never be bricked. Docker running the Application to support IP Camera and IP Console - the Docker application software can be developed with the Cross Compilation and continuously develop and integrate with many releases. The objective of the Docker allow me to test out the docker storm to ensure the two processes to be implemented to the IP Camera or Console, thus allowing High Availability to be implemented to the firmware. The objective of OS that never-bricked the system as it runs on the read-only file system thus allowing the upgrade of the docker application.\nAnd finally all the OS and Docker software packages are still maintained in two banks of memory to support the traditional firmware development, thus we upgrade both OS and application if required.\nI apply the Data-Centre Operation Administration and Maintenance (OAM) on the OS upgrade and Application upgrade to the Firmware OAM. "},{"id":2,"href":"/posts/temporalskill/","title":"Temporal Skill","section":"Blog","content":" Introduction # Finite State Machine and/or Workflow provides the deterministic paradigm to the software application development. Temporal addresses the Workflow part of the paradigm. Hopefully Temporal also addresses the Finite State Machine part of the paradigm. Let research into the technologies to find out if one could start with:\nThe Workflow specification to the Temporal framework OR The Finite State Machine specification to the Temporal framework Further study into few internet pointers, It seems that TO-DO must be required to see how FSM and Temporal Workflow Temporal Cluster # At the heart of the Temporal framework is the cluster. It provides the deterministic mechanism to the workflow using kafka and g- rpc //TO-DO further study required. The Temporal cluster can be run as\nStandalone process For Mac brew install temporal OR curl -sSf https://temporal.download/cli.sh | sh temporal server start-dev For a full list of options, run: temporal server start-dev --help The Temporal Server should be available on localhost:7233 and the Temporal Web UI should be accessible at http://localhost:8233.\nFor Linux (To be added) For Windows (To be added) Docker/Kubernetes: prefer method to run Temporal cluster More to find out at here Temporal Lite # Reference 1 Temporal Getting Started Guide The objectives to run Temporalite with the ability to debug using JetBrains GoLand:\nTo understand how various temporal components work together To run the temporalite as docker (We still think to run it as temporalite docker as part of the development) To debug the application development To perform integration test during the development etc\u0026hellip; Temporal API # [Temporal API Github] (https://github.com/henrynguyenattheitservice/temporal-api-java.git)\ngRPC Services sepecifies in the protobuf files. # We build the temporal API using JetBrains IntelliJ and JetBrains GoLand and see how the generated code used in the development of Java-SDK and Go-SDK. The objectives of the TemporalAPI are\nTo understand the SDK Wrapper To understand the Temporal Server activities via debugging the Temporalite using JetBrains GoLand etc\u0026hellip; TemporalLite Database # The objectives of the Temporal Database are\nTo understand the data and/or information are being persisted To understand the data and/or information are being persisted when the temporal server crashes and recoveries etc\u0026hellip; Java-SDK # DevEnv with JetBrains IntelliJ with Gradle OR Maven\nReference 1 DevEnv \u0026ldquo;Set up a local development environment for Temporal and Java\u0026rdquo; Reference 2 \u0026ldquo;Run your first Temporal application with the Java SDK\u0026rdquo; Reference 3 \u0026ldquo;Build a Temporal Application from scratch in Java\u0026rdquo; Temporal Java-SDK # Step1: Code generation all the prootbuf and gRPC serviice using JetBrains IntelliJ # Step2: Study Temporal Building Block or Components # Workflow # Worker # Client # Saga # Step3: Debug Temporalite together with Running HelloWorld sample # Run Temporalite in the Goland debug mode # Run HelloWorld workflow and activity in the IntelliJ # Go-SDK # DevEnv with JetBrains Goland with Makefile\nReference 1 DevEnv \u0026ldquo;Set up a local development environment for Temporal and Go\u0026rdquo; Reference 2 \u0026ldquo;Run your first Temporal application with the Go SDK\u0026rdquo; Reference 3 \u0026ldquo;Build a Temporal Application from scratch in Go\u0026rdquo; Typescript-SDK # DevEnv with JetBrains WebStorm\nReference 1 DevEnv \u0026ldquo;Build a Temporal Application from scratch in TypeScript\u0026rdquo; Reference 2 \u0026ldquo;Build a Temporal Application from scratch in TypeScript\u0026rdquo; Python-SDK # DevEnv with JetBrains PyCharm\nReference 1 \u0026ldquo;Set up a local development environment for Temporal and Python\u0026rdquo; Reference 2 \u0026ldquo;Build a Temporal Application from scratch in Python\u0026rdquo; "},{"id":3,"href":"/projects/android/usb/","title":"Android application used to Commission, Provision and Diagnostic operations on the Battery meters using USB","section":"Projects","content":" Introduction # Developed the Local Craft Terminal application to perform automatic Commission, Provision and Diagnostic operations on the battery charging to military devices using the Android/Java to interface and interoperate with the Firmware/C via USB and Javolution (Java to C Parser and Formatter).\nProject Team # Duration ~2-3 months 1 x System Architect Document requirements and specifications Provide guidance to Firmware Developers and Testers 2 x Senior Firmware Engineer was responsible Developed firmware for the digital meter using CoAP/LwM2M/IPSO Developed firmware for interface with the android 1 x Senior Software Engineer was responsible for the Proof of Concept release Set up the Development Environment for USB using Android Phone with 6 ports or 8 ports Battery Management devices Set up the Development Environment to work with raw USB device to charge and possible process data at USB Type 3/10 Mbps. Set up the Development Environment for the Android to interface with the Firmware using Javolution (open source used to format the Java to C/CPP and parse C/CPP to Java) Set up the Development Environment for the Android to engineer with Internationalisation with Locale support - UI strings, info/warns/error codes and messages are stored to values/strings Android update to date structure and releases to support the Android X components Android to use GreenRobot EventBus to asynchronously send events between Android Components and USB The User Interface and Usability was engineered with the knowledge when I worked at the Telecom Research Lab to engineer simple UI and deterministic usability to allow soldier on the field to operate on 5-6 inch screen, hostile environment Work with the Firmware Team to develop the android/client side protocol to transport the model for local craft terminal application the battery meter firmware. Technologies \u0026amp; Development Environments # Android USB Simple serial technique with serial port configuration Raw USB technique to allow maximum speed: this part of the project is a research into USB and Android USB 1.0/Low-Speed: 1.5 Megabits per second (Mbps) USB 1.1/Full-Speed: 12 Mbps. USB 2.0/Hi-Speed: 480 Mbps. USB 3.0/SuperSpeed: 5 Gbps. USB 3.1/SuperSpeed: 10 Gbps. Parse and Format C/CPP/Firmware/Hardware to and from Java/Android/Samsung Phone and Sony Phone Release 1: I spent about 12 weeks to develop the PoC. The most difficult components were: DevEnv01- Javolution to format and parse message that both Android LCT Application and Firmware can work together DevEnv02- the USB interface that can support raw USB characteristics and work with C/CPP libusb implemented at the Firmware - please note that the knowledge is not document anywhere in the android. DevEnv03- User Interface workflow to allow the solider to deterministic control the battery meters with glove and military environment. DevEnv04- Engineer the Android Application with International/Locale for all string, Info/Warn/Error messages "},{"id":4,"href":"/projects/android/aws-mqtt/","title":"AWS MQTT and Cognito","section":"Projects","content":""},{"id":5,"href":"/projects/","title":"Projects","section":"","content":""},{"id":6,"href":"/projects/cpp/lsiscan/","title":"LSI AI Scanning System","section":"Projects","content":" Introduction # Enhanced the Parcel Scanning research result for Melbourne University and Collaboration with Melbourne University Consortium, Extel Technologies and LSI. The Parcel Scanning research hypothesize into the Artificial Intelligence by training the digital scan to detect organic material to be trained to detect drugs and metal material to be trained to detect gun and explosion. The enhancement comprised of turning the research result into the commercial product including proving the result was correct with better technique\nProject Team # Duration ~6 months 1 x System Architect ~ Extel Technologies CTO was responsible 1 x Project Manager/Tester ~ LSI Subject Matter Expert and Melbourne University research for the scanning and digital signal processing Document the research result CTO and SME provide guidance to the Senior Software Engineer and Developer 1 x Senior Software Engineer and Developer Work under the guidance of the Extel System Architect and LSI SME Reverse engineering and undo all necessary components of the current solution and enhance the research result each day and each week under the guidance of the System Architect and SME whenever possible Turn the research to the product by systematically separate the Image Processing Libraries and the LSI Scanning Application from the Linux Operating System The LSI Application and the Libraries are running as part of the Linux Account Provide all graph and plot for the organic and metal against all the reference/training material. As the result of the training Technologies # Reverse Engineering # As there was no documentation, we created a macro to print. We ran the application to study the concurrency nature of the digital signalling processing and isolating all the experiment implementation We also attempted to use the Rational Rose to document class diagrams and sequence diagram to understand the software architecture of the current research application The server was a powerful server with 4CPU/8Core per CPU, 128GB of Memory and Linux Centos 6 (closet to the commercial Red Hat) We removed all root permission to the application by We setup the DevEnv using Jetbrains CLion IDE running on Linux We updated the cmake to latest and ensure the all the libraries are compile and install to the lsi include files and libraries Create lsi account and installing and configuring all the libraries to the lis account We ran the application with all the necessary hash define (#define/#ifdef) to print and turn-on/off the printing Once we had the Dev-Env established: We replayed all the data captured to understand the code coverage and concurrency with threading We ensured that all memory and threads are fully utilised and there is no memory leakage on every scan. We applied various Fast Fourier Transform techniques to prove the current application We applied graph and plotting using OpenCV and VTK libraries We trained the LSI scanner to understand the reference organic and metal and other interested materials. We acquired and compare the result by graphing and plotting the real time scanning result against the reference result. Looking back: We wonder about the achievement: \u0026ldquo;Given that I did not touch the development for more than 10 years. I was put into a very deep and dark end of the knowledge universe where the application contained no documentation, the research was a mixture solutions and techniques developed by various researchers and software developers and I was still being able to develop and deploy the solution under the guidance of the Extel CTO and LSI SME \u0026ndash; Special thank to the Extel CTO and LSI SME to provide all the guidance on the Digital Signal Processing techniques and guidance each day. By the way we shorted the development planned for 6 months down to 4 months.\u0026rdquo;\n"},{"id":7,"href":"/projects/java/iotwithgpsandsensors/","title":"Iotwithgpsandsensors","section":"Projects","content":""},{"id":8,"href":"/projects/java/sommetrics/","title":"Sommetrics","section":"Projects","content":""},{"id":9,"href":"/projects/java/vha_ph2/","title":"Vha_ph2","section":"Projects","content":" Introduction # Unico-\u0026gt;CGI developed and deployed VHA to TPG to support Phase-1 Prepaid mobile service and then extend the support to Phase-2 Postpaid mobile.\nProject Team # Duration ~2-3 months and 4 production releases 1 x Project Manager 1 x System Architect was responsible Document requirements and specifications Provide guidance to Developers and Testers Interact with TPG and Matrixx Expert to acquire requirements and specifications and to provide technical support to TPG 1 x Senior and 1 x Experience Java Developer was responsible the Phase-1 Prepaid development 1 x Senior Java Developer was responsible the Phase-1 Postpaid responsible for Learning the Phase-1 Prepaid solution and develop Phase-2 Postpaid solution from the Experience Java Developer Set up the Development Environment with Oracle Database running as docker Fixing defects from Phase-1 to study the Prepaid migration solution Develop the Subscriber Loader, Filter, Batch Manager and Matrixx Interface components to support the Postpaid migration 2 x Testers 1 x Functional and Integration Tester 1 x Model Support Tester / Production Support Tester Technologies # Oracle Database running using Docker # Spring Boot 2 running as a Batch Job # Red Hat Camel 2 used to transform data through various migration stages # "},{"id":10,"href":"/projects/java/adsl-element-manager/","title":"Adsl Element Manager","section":"Projects","content":""},{"id":11,"href":"/projects/android/nfc/","title":"Android application used to Commission, Provision and Diagnostic operations on the South East Water digital meters using NFC","section":"Projects","content":" Introduction # Developed the Local Craft Terminal application to perform Commission, Provision and Diagnostic operations on the South East Water digital meters using the Android/Java to interface and interoperate with the Firmware/C via NFC sensor and Javolution (Java to C Parser and Formatter).\nProject Team # Duration ~2-3 months and 3 production releases 1 x Program Manager / 1 x Project Manager 1 x Senior Firmware Engineer was responsible Document requirements and specifications Provide guidance to Firmware Developers and Testers 2 x Senior Firmware Engineer was responsible Developed firmware for the digital meter using CoAP/LwM2M/IPSO Developed firmware for interface with the android 1 x Senior Software Engineer was responsible for 3 production releases Set up the Development Environment for NFC using Android Phone with NFC built in and NFC sensor tag Set up the Development Environment for the Android to interface with the Firmware using Javolution (open source used to format the Java to C/CPP and parse C/CPP to Java) Set up the Development Environment for the Android to engineer with Internationalisation with Locale support - UI strings, info/warns/error codes and messages are stored to values/strings Android update to date structure and releases to support latest android (I just finished reworking on the porting the sew-lct application to the latest android structure from v4/v7 to androidx at the time write this article) The User Interface and Usability was engineered with the knowledge when I worked at the Telecom Research Lab to engineer simple UI and deterministic usability to work on 5-6 inch screen, water/unclean environment and NFC only works with deterministic stable field by tapping Base Menu Ultrasonic Menu Cathodic Menu Pressure Menu Work with the Firmware Team to develop the simple protocol to transport the model for local craft terminal application the digital meter firmware. the protocol to support the NFC constraints (short message) and intermittent characteristic and behaviour specifies single message and multiple messages checksum send and acknowledge the model to support the data/information to be inter-operated specifies Device model: Hardware/Firmware/Daughter-Board, Battery, Clock, Network Commission/Provision/Diagnostic/Calibrate state and model 1 x Testers 1 x Manufacture Operators - we use the sew-lct to commission the digital meters before dispatch to South East Water. Technologies \u0026amp; Development Environments # Release 1: I spent about 8 weeks to develop the application before Covid-19. The most difficult components were: DevEnv01- Javolution to format and parse message that both Android LCT Application and Firmware can work together DevEnv02- Protocol that both work over constraint transport layer DevEnv03- User Interface workflow using Tab and Nested Tab concept DevEnv04- Engineer the Android Application with International/Locale for all string, Info/Warn/Error messages DevEnv05: Engineer the Android components at 2017-2018 (v4/v7 Design and Android) Android technology milestones. I did quick upgrade few days ago to support the modern Android components (AndroidX - I will upgrade my github after asking Extel Technologies and Client permission to partially publish the content - to be provided the github link) Application Development Release 2: I could not remember anything until few days ago Support for other Daughter Boards: Cathodic, Ultrasonic boards Release 3 Support for other Daughter Boards: Pressure board and features Please this is just a sample of the second production release Demonstration # "},{"id":12,"href":"/projects/java/iot-aws-service/","title":"Iot Aws Service","section":"Projects","content":""},{"id":13,"href":"/projects/java/modini/","title":"Modini Project","section":"Projects","content":" Introduction # Unico-\u0026gt;CGI developed and deployed Modini to Telstra to support 3G and 4G Mobile services more than 10 years ago.\nRecently Telstra deploy 4G-\u0026gt;5G and 5G Stand Alone Mobile services and Modini is extended to support the 4G-\u0026gt;5G and 5G Stand Alone.\nThe projects was planned into four releases together with fixing some critical and major defects.\nProject Team # Duration ~6-8 months and 4 production releases 1 x Project Manager 1 x System Architect was responsible Document the 4G-\u0026gt;5G and 5G SA requirements and specifications Provide guidance to Developers and Testers Interact with Telstra Subject Mater Expert to acquire requirements and specifications and to provide technical support to Telstra 1 x Senior Java Developer was responsible Work with the System Architect and Testers to analyze the requirements and specifications Study the current solution from the source code and technologies in the Dev, Test and Production. When the DevEnv is set up with remote debug, and yes the project is heading home with the achievement. Use JIRA to plan features and defects to each sprint Hourly to daily analyse each feature and defect with the tester Develop the features with the unit testing Develop the solution to for each defect with functional, model suport and production support testing Develop and deploy the sprint releases with the integration testing Use Bitbucket to build and deploy the releases to the functional tester also to work with the tester for any short cycle functional testing Use Jenkins to CI/CD build formal releases to the functional and model support testers Provide third level support and guidance to Model/Production Support Testers and Telstra customers via System Architect and Model/Production Support Tester Interact with OCS Developers (billing and charging database and application) and Mediator Developers (sending requests and receiving responses to test mobile services) to develop the technical requirements and specifications. 3 x Testers 1 x Functional and Integration Tester 1 x Model Support Tester 1 x Production Support Tester Technologies # The objectives were:\nStudy the legacy technologies and set up the Development Environment using Java 7, JBoss EAP 6.3, JSF 2.1, Groovy, Gradle 2 Study the solution from the code as there have not been documentation When developing the new features we must ensure the all backward compatibilities for the 3G, 4G and some 4G-\u0026gt;5G using Home Location paradigm and 4G-\u0026gt;5G and 5G SA using CDB paradigm. Front End Technologies # J2EE - Java Server Face # The User Interface is developed using HTML, Javascript, JSF and JSF Tag Libraries. DevEnv Template for JSF We use to test out some complex UI features where they were difficult to develop with many legacy concepts.\nJavascript/HTML/Groovy # The User Interface is also developed to support Dynamic Business Logic using Groovy thus allowing Telstra to customise the business rules without rebuilding Modini.\nBack End Technologies # J2EE - JBoss EAP running a standalone deployment and proof of concept Load Balancing deployment # DevEnv Template for JBoss EAP 6.3 StandAlone We use to understand how JBoss is setup and configure for the development. DevEnv Template for JBoss EAP 6.3 and 7.x StandAlone with Load Balance DevEnv We develop the concept to guard against the performance issues. We run many standalone instances and depoy F5 LB to schedule session infinity load balance. We find that the approach is simple (KISS) comparing to the recommended JBoss Cluster. The hardware is an Out Of Life HP Blade with many CPU/Thread running Solaris 10 without Zone or Solaris Container. DevEnv Template for JBoss EAP 7.x Cluster DevEnv We develop the LB concept based on the Redhat recommendation but we know that Cluster can be complex when one node or more nodes in the Cluster do not operate. Engineering the development to ensure the backward compatability to the existing legacy and forward compatability to the new way of working, # Remote Home Location Reference Model \u0026amp; Paradigm Home Location Paradigm to support 3G and 4G Mobile services Support/Maintain backward compatability CDB Reference Model \u0026amp; ParadigmCDB to support 4G-\u0026gt;5G and 5G SA: Support/Maintain forward compatability - enhancement is carefully considered to ensure the backward legacy and forward compatability. Other interfaces to be considered during the development # SOAP/WSDL Interfaces to Mediator resulting in three or four complex schema changes and code generation developed to the modini JMS Interface to Mediator Command Line Interface to Mediator Looking back: We wonder about the achievement: \u0026ldquo;To engineer, develop and deploy four releases to Telstra without any patch i.e. without any defects / To engineer, develop and deploy the solution to support backward and forward compatability / To engineer, develop and deploy the solution to support two reference models and paradigms to a legacy solution just from reading more 10 years old code and technologies - What a Miracle and What a Team!\u0026rdquo;\n"},{"id":14,"href":"/projects/java/sew-leshan/","title":"Sew Leshan","section":"Projects","content":""},{"id":15,"href":"/posts/projects/","title":"Commercial Projects","section":"Blog","content":" Introduction # Commercial projects are classified into:\nJava Projects Infrastructure Projects Cloud solution Projects Java Projects # Modini for Telstra @Unico/CGI # Enhanced the existing Service Assurance Management System supporting from 3G and 4G to 5G and 5G SA mobile services using Java7/J2EE with JSF/Javarscript/Groovy for the FrontEnd and JBoss/EJB/JMS/SOAP/CLI over SSH to interface to Mediator Devices. The persistent storage is MySQL.\nMobile Prepaid and Postpaid Mobile Service Migration for TPG @Unico/CGI # Enhanced the existing Phase-1 Prepaid mobile service migration to support Postpaid as well using Java8 Batch Spring Boot v2 and Red Hat Camel v2 to interface to the Oracle database running as a docker and Matrixx using JMS. The Subscriber Loader component loads the mobile service and subscriber details to be used in the migration. The Batch Manager perform the migration for prepaid mobile service and postpaid mobile services. The Filter loads subset of the prepaid and postpaid to be migrated. The Metrixx component sends the migrated result to a new Matrix Billing and Charging System.\nData Acquisition System for Sommetrics AER Sleep IoT Device @Extel Technologies/Sommetrics # Developed the IoT Data Acquisition to extract the sleeping data from the Android device via USB and send the sleeping result set to AWS Device Gateway via MQTT. The IoT Android was developed to use the AWS Cognito to load the Certificate for encryption, AWS Device Gateway Policy to authenticate the IoT device, AWS Device Gateway Rule to authorise and persist the result set to the DynamoDB. The scalable Restful API cluster was developed in the back to process the result set at the BackEnd and the Sencha ExtJS was developed to allow the user to access the report.\nData Acquisition System for the IoT Device with GPS Tracking and Texas Sensor Tags @Extel Technologies # Developed the IoT Data Acquisition to extract the GPS data from the Android device and extract IoT Texas Sensor Tags data via Bluetooth the result set to AWS Device Gateway via MQTT. The IoT Android was developed to use the AWS Cognito to load the Certificate for encryption, AWS Device Gateway Policy to authenticate the IoT device, AWS Device Gateway Rule to authorise and persist the result set to the DynamoDB. The scalable Restful API cluster was developed to display the tracking to the Google Map together with the IoT Texas Sensor Data. Code Generation and Interception Management System @Ericsson Australia # Developed the framework to generate Solution Architecture Document (SAD includes Subsystems and nested Subsystems) and Detailed Design Document (DDD include Class Diagram and Sequence Diagram) documentation from Rational Rose Developed the UI CRUD Framework (I used the MFC/C/Windows framework developed by Nokia Engineers and I implemented the same concept using Swing/Java 1.4 - I would like to acknowledge the Nokia Engineer - I was a PM managed the Local Craft Terminal or Node Manager at Nokia) Developed the EJB CRUD Framework Developed code generation for One-One, One-Many and Many-Many relationships to generate the schema for database to generate the UI CRUD to generate the EJB CRUD Developed the Interception Management Application using the Code Generation Element Manager for the DSLAM to support ADSL/ADSL2/ADSL2+, Long Reach with SHDSL Repeater and Backhaul with ATM/ATM-IMA and IP @Extel Technologies # Developed the Element Manager to perform Provision, Commission, Operation, Administration and Maintenance for the Long Reach ADSL DSLAM. The Element Manager was developed with\nVarious RFCs for SNMP v1/v2/v3 and ADSL/ADSL2/ADSL2+ for the tributary access network, SHDSL for the repeater network and ATM/ATM-IMA/IP for the backhaul network J2EE Back End: Java 1.4/1.5 and Apache Tomcat MVC Front End: Struts v1/v2 Framework for MVC, JSP, HTML/HTTP, Javascript and WebSocket with value pair for the real time notification feature. Database with MySQL or Oracle CPP Projects # LSI Scan@Extel Technologies/LSI # Enhanced the Parcel Scanning research result for Melbourne University and Collaboration with Melbourne University Consortium, Extel Technologies and LSI. The Parcel Scanning research hypothesize into the Artificial Intelligence by training the digital scan to detect organic material to be trained to detect drugs and metal material to be trained to detect gun and explosion. The enhancement comprised of turning the research result into the commercial product including proving the result was correct with better technique\nXMate Element Manager for AXE Switches@Ericsson Australia # Enhanced the XMate with new features and fixing defects. Developed the new architecture using RPC CPP and RPC Java 1.4. Developed the compiler to generate the CPP and Java stub and skeleton (aka gRPC) code from the RPC XDR (aka protobuf) template. The Java and CPP were serialized and deserialized using the commercial STD Libraries. Developed the Proof Of Concept using the RPC CPP and RPC Java - the new generation of XMate.\nElement Manager for the ISDN Basic Access Rate @Telecom Australia/Telstra # Developed the Element Manager to perform Operation, Administration and Maintenance for the ISDN Basic Access rate using TMN Q3 Short Stack. Specified the interface to allow the IDSN BA to send alarms to the TUSC Alarm Management System.\nAndroid Projects # Android Application used to perform the commission and provision and maintenance of the Water Digital Meter via NFC @Extel Technologies/South East Water # Developed the Local Craft Terminal application to perform Commission, Provision and Diagnostic operations on the South East Water digital meters using the Android/Java to interface and interoperate with the Firmware/C via NFC sensor and Javolution (Java to C Parser and Formatter).\nAndroid Application used to manage the battery devices via USB @Tectonica # Code Generation and Interception Management System @Ericsson Australia # Developed the Local Craft Terminal application to perform automatic Commission, Provision and Diagnostic operations on the battery charging to military devices using the Android/Java to interface and interoperate with the Firmware/C via USB and Javolution (Java to C Parser and Formatter).\nAndroid Application used to acquire data from IoT device and transport data to the AWS # Android Application used to acquire sensor and gps data from IoT device and transport data to the AWS # Infrastructure Projects # Infrastructure Projects at ANZ Bank # CMP # All Australian/Global credit transactions are processed and maintained in the CMP solution before transport to the end systems.\nMoney Laundry Protection # Tracking all money transaction related to the Money Laundry\nBank Transaction Reconciliation # All ANZ banking transactions are validated and reconciled.\nFinacle Retail Banking at China/Hong Kong/Lao/Vietnam/Singapore # Exception step to the above ANZ hired the third party Data Centres for cost affective reasons. The MPLS network is used instead of the dedicated dark-fibre network like in Australia. Most projects at ANZ Bank were implemented with the following workflows:\nWorked with the Solution Architect to perform the Order of Magnitude estimation with +/- 30% Worked with Oracle or Oracle Retailed Company to perform Detailed estimation with +/- 10% Worked with the ANZ Environment Manager team to plan the private virtual cloud networks to deploy the infrastructure Racked and stacked Commodity to Midrange servers to Primary/Secondary Data Centres with High Available Network, Storage, Power consideration Build the OS, Network, Storage into the planned environments, Production, Performance/Recover, Testing and Development Support the Environment Management and Development team from the Infrastructure daily tasks Specified and document the Disaster Recovery Plan with various protection levels, bronze, gold, platinum etc\u0026hellip; Performed Disaster Recovery Test with Network, Storage and Application teams to ensure that the Planned Outage to meet the plan protection levels. Transitioned the projects to the Operation team Performed Level 3 support to the Operation team Infrastructure Projects at Australia Post # Most projects at Australia Post were implemented with the following workflows:\nDigital Transformation Projects # Performed the Order of Magnitude estimation with +/- 30% and wrote the Solution Architecture document with consideration to Computing, Network/Security, Storage. Performed the Detailed estimation with +/- 10% and wrote the Design document with consideration to Computing, Network/Security, Storage. Performed the integration solution to existing Australia Post IT solution Data Centre Planning/Design/Deployment/Integration at the Parcel Sorting # Melbourne (MPS) - Completed # Sydney Parcel Sorting Centre - Cancelled # Brisbane Parcel Sorting Centre - Cancelled # Performed the Order of Magnitude estimation with +/- 30% and wrote the Solution Architecture document with consideration to Computing, Network/Security, Storage specified by the Parcel Solution vendor. Performed the Detailed estimation with +/- 10% and wrote the Design document with consideration to Computing, Network/Security, Storage specified by the Parcel Solution vendor. Designed the Parcel Data Centre with Power consideration Primary, Secondary and Diesel UPS Integrated the Parcel Data Centre IT solution with Australia Post IT solution Cloud Solution Projects # Data Acquisition System for Sommetrics AER Sleep IoT Device @Extel Technologies/Sommetrics # Developed the IoT Data Acquisition to extract the sleeping data from the Android device via USB and send the sleeping result set to AWS Device Gateway via MQTT. The IoT Android was developed to use the AWS Cognito to load the Certificate for encryption, AWS Device Gateway Policy to authenticate the IoT device, AWS Device Gateway Rule to authorise and persist the result set to the DynamoDB. The scalable Restful API cluster was developed in the back to process the result set at the BackEnd and the Sencha ExtJS was developed to allow the user to access the report.\nData Acquisition System for the IoT Device with GPS Tracking and Texas Sensor Tags @Extel Technologies # Developed the IoT Data Acquisition to extract the GPS data from the Android device and extract IoT Texas Sensor Tags data via Bluetooth the result set to AWS Device Gateway via MQTT. The IoT Android was developed to use the AWS Cognito to load the Certificate for encryption, AWS Device Gateway Policy to authenticate the IoT device, AWS Device Gateway Rule to authorise and persist the result set to the DynamoDB. The scalable Restful API cluster was developed to display the tracking to the Google Map together with the IoT Texas Sensor Data. "},{"id":16,"href":"/posts/pocs/","title":"Proof Of Concept and Research Projects","section":"Blog","content":" Introduction # Here are the main categories to be developed as Proof of Concept or Research (Hypotheses/Experiments/Results)\nJava/Go/Python Projects Infrastructure Projects Cloud solution Projects Finite State Machine with Xstate and Typescript, Java, Python # Research on various techniques on how to develop application suing Finite State Machine.\nFinite State Machine # State machine is a concept used for designing complex system\nState Machine parts are: States, Events, Initial State, Transitions, Final State. State is a representation of a system in specific point of time Events are actions that causes transitions between states Transition is a change between states An example of water state machine [Code sample implemented in typescript and xstate] (https://github.com/henrynguyenattheitservice/watermachine) Water machine states are specified as follows: const waterMachine = createMachine({ id: \u0026#39;water\u0026#39;, initial: \u0026#39;liquid\u0026#39;, states: { ice: {}, liquid: {}, gas: {}, plasma: {}, } }); Note that there are five different types of states: Initial, Final, Child, Terminal or Last State (double border),?. Events are HEAT and FREEZE Water state machine is full specified as follows\nimport {createMachine} from \u0026#34;xstate\u0026#34;; import {useMachine} from \u0026#34;@xstate/react\u0026#34;; const waterMachine = createMachine({ id: \u0026#39;water\u0026#39;, initial: \u0026#39;liquid\u0026#39;, states: { ice: { on : { HEAT: { target: \u0026#34;liquid\u0026#34; } } }, liquid: { on: { HEAT: { target: \u0026#34;gas\u0026#34; }, FREEZE: { target: \u0026#34;ice\u0026#34; } } }, gas: { on: { HEAT: { target: \u0026#34;plasma\u0026#34; }, FREEZE: { target: \u0026#34;liquid\u0026#34; } } }, plasma: { on: { FREEZE: { target: \u0026#34;gas\u0026#34; } } } } }); Application can only be in One State of a time. Transitions happens only when Events are allowed. Everything is transparent and machine will never go out of defined bounds and decides which state the application is in. Action is function that can be called on an event or transition - Side effect that we can run on the State Machine Actions on Events - calling actions on events by function definition or function name with definition below machine Each state can handle special type of actions: Entry Action executing up on entering a state or Exit Action executing upon exiting a state Context is a place for storing data - Data in context can be initial when the machine is first created but can also be assigned by an action Assign function gets current context and event as parameter Guards is conditional actions and transitions - Guard is a function checking if action or transition is allowed to happen. Guards allow to call actions and make transitions based on some condition. Guards can be passed in special condition property. Transition kinds are Internal, External, Eventless, and Forbidden (TBC) Services are invoked by using special Invoke property. Handling result on Done for resolved Promise and onError for rejected Promise. Machine can interpret states in parallel using type = parallel and onDone = trigger the state in parallel. Javascript and Typescript # Hypothesis: Develop web application and FSM using typescript - Xstate brings State Machines to Javascript/Typescript world. Hypothesis Develop FSM using Typescript/Javascript Hypothesis Develop Web App using Typescript and FSM Typescript Python # Hypothesis: Develop web application and FSM using Python Hypothesis Develop FSM using Python Hypothesis Develop App using Python and FSM Python Java # Hypothesis: Develop web application and FSM using Java Hypothesis Develop FSM using Java Hypothesis Develop App using Java and FSM Java ChatGPT Voice Chat Bot With NextJS \u0026amp; OpenAI # ChatGPT Integration # Use Protobuf and gPRC to mock up CoAP/LwM2M/IPSO solution # Temporal workflow and How to break down Components as part of the DevEnv # Temporal workflow and Saga Finite State Machine Findings # Full Stack with React # React and React-Native with IoS and Android # To figure out a solution I tried to understand how Expo runs the React Native code base inside the Expo Application on our mobile. I went through Expo’s documentation How Expo works? and mapped it to the output I got for my own application\nAfter executing yarn start I get a QR code to scan followed by\n‘Your app is now running at URL: exp:// 192.168.0.172:19000’\nOn scanning the QR code the Expo app on my mobile makes a request to 192.168.0.172:19000. This returns a JSON which includes metadata about our application and the URL where React Native Packager Server is running. This is provided against the key bundleUrl\nBy default React Native packager runs a server on localhost:8001\nBased on the value of bundleUrl Expo had launched the React Native packager server on 192.168.0.172:19001\nNext the Expo app on mobile fetches the app’s Javascript from bundleUrl served on 192.168.0.172:19001\nI get a Network error because while my application is running on my mobile it makes a request to 127.0.0.1:8000. Presumably it either refers to the loopback address on Android where there isn’t any server running on port 8000 or the address is unidentified and hence a Network error\nIn order to access the mock server it has to be available either on my development machine’s IP address (where it will be accessible because my mobile and laptop are on the same network as required by Expo) or on a universally accessible URL over the internet By using ngrok or localtunnel\nBy using either of these modules we can expose a server running on localhost on the web.\nNext we can use the corresponding URL to access the mock-server from our application running inside Expo\nI went ahead with localtunnel\nInstalling localtunnel globally on my dev machine\nyarn global add localtunnel\nI used json-server to setup and run a mock server. The following command sets up the mock server on localhost and port 8000\njson-server \u0026ndash;port 8000 ./db.json \u0026ndash;watch\nNext to expose the mock server to the web use localtunnel\nlt \u0026ndash;port 8000 \u0026ndash;subdomain application-mock-server\nThe above command will return a URL accessible across Internet of the form https://application-mock-server.localtunnel.me. This URL can be plugged inside the React Native code base and will be accessible from the application running inside Expo on the mobile.\nFull Stack with VueJS # Full Stack with NextJS # Java/Go/Python Projects # How to develop Firmware with Yocto and Docker on Pi and Dev Board # How to develop Firmware with Yocto and Distributed Data System running Docker on Pi and Dev Board # How to develop Android-Native and USB Serial Protocol # How to develop Android-Native and USB Interrupt USB API # How to develop Android Tactical Assault Kit (ATAK) # "},{"id":17,"href":"/posts/grpc-skill/","title":"Grpc Skill","section":"Blog","content":" Introduction # Hi everyone!\nHere are some thoughts on the solution for protobuf and gRPC:\nSet the Development Environment for\nJava: we start to setup the Java DevEnv to build up the confidence and know-how. The reasons are that we know Java Development come with two structures of building application MAVEN and GRADLE. We need to feel how gRPC works in the Java DevEnv. Refer to the URL link for detailed notes. C (more likely to be used for the firmware development than CPP), CPP (CPP in the wrong hand can cause issues in the firmware development): We have to dig deep into the memory lane to setup the CPP DevEnv. We start with CMAKE and LINUX. We need more time to study the BAZEL. Refer to the URL link for detailed notes. Go: We have not fully completed the Go DevEnv but we perform a quick test to build the HelloWorld and perform the interopability test between Go and CPP / Go and Java to ensure that the protobuf is doing what it actually documented. Python - Python (to be use for testing): we did some training with Python, Test out the protobuf and the interoperability across java, go, python and cpp.\nTesting out the interoperability between various environments (Java vs Go vs Python vs C/CPP)\nWe PoC the IoT\nBootstrap - Device Authentication Registration and Registration Update - Device Authorization CRUD and O/N - Create, Remove, Update, Display and Observable/Notification on the smart objects Bootstrap\nsyntax = \u0026#34;proto3\u0026#34;; import \u0026#34;lwm2m/OMA0000Security.proto\u0026#34;; import \u0026#34;lwm2m/OMA0002Device.proto\u0026#34;; package au.com.theitservice.iot; option java_package = \u0026#34;au.com.theitservice.iot\u0026#34;; option java_multiple_files = true; service BootstrapService { rpc bootstrap(lwm2m.OMA0002Device) returns (lwm2m.OMA0000Security); } Registration and Registration Update\nsyntax = \u0026#34;proto3\u0026#34;; import \u0026#34;google/protobuf/timestamp.proto\u0026#34;; import \u0026#34;google/protobuf/any.proto\u0026#34;; package au.com.theitservice.iot; option java_package = \u0026#34;au.com.theitservice.iot\u0026#34;; option java_multiple_files = true; message MessagesRegistrationAnyObjectsRequest { google.protobuf.Timestamp last_updated = 1; repeated google.protobuf.Any omaObjects = 2; } message MessagesRegistrationAnyObjectsResponse { google.protobuf.Timestamp last_updated = 1; int32 stausCode = 2; string statusMsg = 3; } service RegistrationService { rpc registration(MessagesRegistrationAnyObjectsRequest) returns (MessagesRegistrationAnyObjectsResponse); } service RegistrationUpdateService { rpc registrationUpdate(MessagesRegistrationAnyObjectsRequest) returns (MessagesRegistrationAnyObjectsResponse); } Or we may select to pass along the object name and we use the name to construct the smart object. syntax = \u0026#34;proto3\u0026#34;; import \u0026#34;google/protobuf/timestamp.proto\u0026#34;; package au.com.theitservice.iot; option java_package = \u0026#34;au.com.theitservice.iot\u0026#34;; option java_multiple_files = true; message MessagesRegistrationRequest { // List of messages to be requested for monitor message RegisteredObject { int32 objectId = 1; string objectName = 2; } repeated RegisteredObject registerObjects = 1; } message MessagesRegistrationResponse { // Acknowledge that messages to be monitored message RegisterStatus { int32 code = 1; string statusMsg = 2; } } service RegistrationNameObjectsService { rpc registrationNameObjects(MessagesRegistrationRequest) returns (MessagesRegistrationResponse); } service RegistrationUpdateNameObjectsService { rpc registrationUpdateNameObjects(MessagesRegistrationRequest) returns (MessagesRegistrationResponse); } **CRUD and O/N (to be specified) **\nsyntax = \u0026#34;proto3\u0026#34;; package au.com.theitservice.iot; option java_package = \u0026#34;au.com.theitservice.iot\u0026#34;; option java_multiple_files = true; import \u0026#34;google/protobuf/timestamp.proto\u0026#34;; import \u0026#34;google/protobuf/any.proto\u0026#34;; message ObjectRequest { google.protobuf.Timestamp last_updated = 1; repeated google.protobuf.Any omaObjects = 2; } message ObjectResponse { repeated google.protobuf.Any omaObjects = 2; } service CRUD { rpc postObject(ObjectRequest) returns (ObjectResponse); rpc getObject(ObjectRequest) returns (ObjectResponse); rpc putObject(ObjectRequest) returns (ObjectResponse); rpc deleteObject(ObjectRequest) returns (ObjectResponse); } service ChangeNotification { rpc changeNotify(ObjectRequest) returns (ObjectResponse); } OMA # GitHub\ngrpc and IDL # Introduction\ngrpc with java # Study Development Environment Development Tool\ngrpc with golang # Study Development Environment Development Tool\ngrpc with python # Study Development Environment Development Tool\ngrpc with android # Study Development Environment Development Tool\n"},{"id":18,"href":"/posts/java-skill/","title":"Java Skill (draft)","section":"Blog","content":" GitHub Referece\nDevelopment Environment # The Java Development Environment is setup as follows:\nWe use IntelliJ IDEA as the primary Integrated Development Environment tool.\nIntelliJ IDEA with Git Servers: to connect to Git Server,GitLab Server, Bitbucket and Github IntelliJ IDEA with Git: to manage Code Control - Local and Remote Git activities. IntelliJ IDEA Debug: to debug and learn everything about Golang IntelliJ IDEA Remote Debug: to remote debug to diagnose code issues and defects in the integration IntelliJ IDEA and Docker Desktop as an Integrated Development Environment: to create the development environment using Docker and Kubernetes e.g. Kafka, Database, JBoss, Web servers (Apache, nginx, jetty) We use TeamCity or Jenkins to perform CI/CD We use HttpClient plugin comes with IntelliJ IDEA for Restful Integrated Testing Docker Desktop: We use Docker Desktop to deploy various environments used for the development and the integration testing: Kafka dockers referring to the diagram for the Docker Desktop containing various Kafka sources provided by Confluent docker, Redpanda C++ Kafka and Redpanda Data Github Debezium Docker etc\u0026hellip; Kubernetes The reasons for composing the docker services and/or kubernetes pods are:\nWe allow each Developer to replicate the Development Environment with docker, thus suitable for microservice team and work breakdown We deploy the application in the Development Environment to the application in the Testing Environment with docker We deploy the application with CI/CD in mind and automate testing When we learn a new computer language, the debug will assist the learning. We setup two approaches to debug Golang: We use the IntelliJ IDEA IDE debug the code When the Developers work with the Testers to trace any issues We use the IntelliJ IDEA or Visual Code IDE to perform the remote debug to a Golang process "},{"id":19,"href":"/posts/leshanapp-iotapp-mobileapp-skill/","title":"leshan Application / Iot Application / Mobile Application Skill (draft)","section":"Blog","content":" Use Cases # Here are the summary of the solution and standards for CoAP, LwM2M and IPSO:\nSolution \u0026amp; Standard to Support CoAP # Device and Protocol to work in a constraint environment – CoAP Constraint of Application Protocol Protocol operates s constraint resources, e.g. Power devices run using battery or Transmit data in an Intermittent and narrow band. CoAP protocol is a Restful-like API with Restful response code Operate in various protocol stacks, UDP/DTLS, TCP/TLS and Websocket, SMS and MQTT Message encodes/decoded and transported between devices using CBOR Concise Binary Object, Text, TLV, JSON\nSolution and Standard to support LwM2M # Device Communication with its Management System – LwM2M Lightweight Machine to Machine Protocol – engineered on the “wisdom” of machine to machine interface Device authentication with Bootstrap without Security and with Security PSK, RSK, X500 Self-Signed and X500 Certificate Device authorisation with Registration and regular Registration Update Device maintenance Firmware/Software Upgrade Device configuration with Device Management and Service Enablement with Read, Read/Write, Execute\nSolution \u0026amp; Standard to support Data/Business Logic Modelling # Device Resource/Data Model with IPSO Internet Protocol Smart Object OMA Open Mobile Alliance provide a registration framework to allow all industry sectors, Energy, Telco, Mobile and Internet\nTo perform Data/Information Model using Device Management/Service Enablement and Report Notification Hypotheses into Use Cases For IoT Application Domain: IoT Use Case # Digital Meters of Water, Power, Gas, Electricity (measurement data), Automotive (measurement with CAN bus, Tracking with GPS) Cargo container tracking on land, on sea, and in the air We hypothesize on a solution to develop Firmware Application running in the e.g. Arm Core ( CPUs A-Core or M-Core\nFor Mobile Application Domain: Mobile Use Case (Mobile Application)→ # Banking, Stock Market domains (leverage on the authentication with security enabling and report notification in real time to inform user) We hypothesize on a solution to develop Mobile Application running Mobile devices e.g. Android/Apple phones and tablets\n"},{"id":20,"href":"/posts/springboot-skill/","title":"Springboot Skill (under-construction)","section":"Blog","content":""},{"id":21,"href":"/posts/yocto-skill/","title":"Yocto Skill (draft)","section":"Blog","content":" Introduction # Hi everyone, here are my thoughts in my mind when I study about Yocto/OpenEmbedded on one of projects\nDesign the system with High Available solution in mind. That is: We ensure the system is designed and operated with dual power supplies. Power if possible we should use N+1 System diagram is on the way We need to have an integrated solution in mind. For example one vehicle view may not be assisted the total solution when combining with many vehicle views (vehicle ~ tank or vehicle ~ boat/ship etc\u0026hellip;i.e. we can not win the battle with the view of one vehicle but we can have a better opportunity to win the battle when all views are combined) Design the OS running on the read only the partition where the filesystem is configured to read only. That is the Yocto/OpenEmbedded OS is loaded to the readonly filesystem partition. By doing so we will less likely to brick the system. Use the docker to develop the application in the cross the platform - cross compilation - need to proven and test out more. By doing so we can constantly testing out the application and develop application using more power laptop and PC. Please note that we still perform firmware upgrade in two approaches - this is the approach I learn when working in the data centre as we dont often upgrade the OS but we constantly upgrade the application: Total upgrade both OS (Yocto/OpenEmbedded) and application (docker) Application upgrade Constantly upgrade with application patches even though we are in testing, preproduction and production (if it is safe to do so). Training # Udemy # Embedded Linux using Yocto Part 1 Embedded Linux using Yocto Part 2 Embedded Linux using Yocto Part 3 Embedded Linux using Yocto Part 4 Learn Embedded Linux using Yocto Prject Makefile and GNU make C/C++ on Linux Linkedin # NA\nYoutube # NA\nProjects # Develop the Embedded Linux OS to run the Yocto/Openembeded/Raspberry Pi Docker # Deploy ADLINK/VORTEX DDS Docker to RasberryPi4 # Develop the Development Environment to allow the Developers to develop the Embedded application using Docker # Study # Toolchain: Compiler and other tools used to create code for the target device Bootloader: Program that initialises the IC board and loads the Linux kernel Kernel: manage resources and interfaces with the hardware Root filesystem: contains libraries and programs that are run once the kernel has completed its initialisation. It is recommended that the kernel or Operating System is kept on the Read-Only filesystem thus minimising the device is being bricked and the Application is kept on the Read-Write filesystem thus optimising the application is being loaded and maintained continuously during the development and deployment. It is similar concept and it is important “when we operate and maintain the Data Centre where we operate and maintain the Operating System releases less frequently than we operate and maintain the Application more frequently with continuous deployment thus leading to the docker delivery in the embedded linux or firmware”. What is Yocto: Yocto is a project provides open source founded in 2010 to allow the developers to create their own custom Linux distributions for any hardware architecture. It is formed by collaborate: Hardware manufacturers and Electronics companies\nOpen Source for Linux Operating Systems thus forming the working group of Linux foundation\nWe specify the Input and Output for the Yocto project as follows:\nInput: Set of data that describes what we want, that is our specification (Kernel Configuration, Hardware Name, Packages/Binaries to be installed) Output: Linux Based Embedded Product (Linux Kernel, Root File System, Bootloader, Device Tree, Toolchain) Platform prerequisites to build the Yocto project(s).\nSoftware Ubuntu 20.04.6 $ lsb_release -a No LSB modules are available. Distributor ID: Ubuntu Description: Ubuntu 20.04.6 LTS Release: 20.04 Codename: focal sudo apt-get install gawk wget git-core diffstat unzip texinfo gcc-multilib \\ build-essential chrpath socat cpio python python3 python3-pip python3-pexpect \\ xz-utils debianutils iputils-ping python3-git python3-jinja2 libegl1-mesa libsdl1.2-dev \\ pylint3 xterm Others software\ngit tar python3 Hardware – I use my Mac Pro with 2 CPUs/6 Cores per CPUs/2 Threads per Core and 64 GB of Memory and Multiple 50 GB (storage per build) as the build can take more than 4 hours\nEmbedded Linux Releases\nReleases 4: 4.0\nKirkstone/4.1 Langdale/4.2 Mickledore/4.3 Nanbield Release 3: 3.0\nZeus/ 3.1 Dunfell / 3.2 atesgarth / 3.3. Hardknott / 3.4 Honister Other releases refer to https://wiki.yoctoproject.org/wiki/Releases\nQEMU project # Notes on how to configure, build, and run qemu\n$ mkdir -p ~/projects/qemu/source $ cd ~/projects/qemu/source $ git clone git://git.yoctoproject.org/poky $ git branch --all $ git checkout langdale or $ git clone -b langdale --depth=1 git://git.yoctoroject.org/poky $ cd poky $ git status $ cd ~/projects/qemu/source $ source poky/oe-init-build-env ../build $ bitbake-layers show-layers NOTE: Starting bitbake server... layer path priority ========================================================================== meta /home/hlkn/Desktop/projects/qemu/source/poky/meta 5 meta-poky /home/hlkn/Desktop/projects/qemu/source/poky/meta-poky 5 meta-yocto-bsp /home/hlkn/Desktop/projects/qemu/source/poky/meta-yocto-bsp 5 Raspberry PI project # Notes to configure, build and run raspberry-pi Download and configure correct branch for raspberrypi, meta-openembedded\n$ mkdir -p ~/projects/rpi/source $ cd ~/projects/rpi/source $ git clone git://git.yoctoproject.org/poky $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-openembeded $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-rapberrypi $ git branch --all $ git checkout langdale or $ git clone -b langdale --depth=1 git://git.yoctoroject.org/poky $ git clone -b langdale --depth=1 git://git.yoctoroject.org/openembedded $ git clone -b langdale --depth=1 git://git.yoctoroject.org/raspberrypi $ cd poky $ git status $ cd ~/projects/rpi/source $ source poky/oe-init-build-env ../build $ bitbake-layers show-layers NOTE: Starting bitbake server... layer path priority ========================================================================== meta /home/hlkn/Desktop/projects/rpi/source/poky/meta 5 meta-poky /home/hlkn/Desktop/projects/rpi/source/poky/meta-poky 5 meta-yocto-bsp /home/hlkn/Desktop/projects/rpi/source/poky/meta-yocto-bsp 5 $ bitbake-layers add-layers NOTE: Starting bitbake server... layer path priority ========================================================================== meta /home/hlkn/Desktop/projects/rpi/source/poky/meta 5 meta-poky /home/hlkn/Desktop/projects/rpi/source/poky/meta-poky 5 meta-yocto-bsp /home/hlkn/Desktop/projects/rpi/source/poky/meta-yocto-bsp 5 $ bitbake-layers show-layers NOTE: Starting bitbake server... layer path priority ========================================================================== meta /home/hlkn/rpi/source/poky/meta 5 meta-poky /home/hlkn/rpi/source/poky/meta-poky 5 meta-yocto-bsp /home/hlkn/rpi/source/poky/meta-yocto-bsp 5 meta-oe /home/hlkn/rpi/source/meta-openembedded/meta-oe 5 meta-python /home/hlkn/rpi/source/meta-openembedded/meta-python 5 meta-networking /home/hlkn/rpi/source/meta-openembedded/meta-networking 5 meta-multimedia /home/hlkn/rpi/source/meta-openembedded/meta-multimedia 5 meta-filesystems /home/hlkn/rpi/source/meta-openembedded/meta-filesystems 5 meta-raspberrypi /home/hlkn/rpi/source/meta-raspberrypi 9 Configure local.conf to support build Build the raspberrypi image will take about 3 hours or more depending on the server. $ bitbake rpi-test-image Loading cache: 100% |############################################| Time: 0:00:01 Loaded 4087 entries from dependency cache. NOTE: Resolving any missing task queue dependencies Build Configuration: BB_VERSION = \u0026#34;2.2.0\u0026#34; BUILD_SYS = \u0026#34;x86_64-linux\u0026#34; NATIVELSBSTRING = \u0026#34;universal\u0026#34; TARGET_SYS = \u0026#34;aarch64-poky-linux\u0026#34; MACHINE = \u0026#34;raspberrypi4-64\u0026#34; DISTRO = \u0026#34;poky\u0026#34; DISTRO_VERSION = \u0026#34;4.1.3\u0026#34; TUNE_FEATURES = \u0026#34;aarch64 armv8a crc cortexa72\u0026#34; TARGET_FPU = \u0026#34;\u0026#34; meta meta-poky meta-yocto-bsp = \u0026#34;langdale:a7d90a69d90ac980f28dd1783c2c5a849f6dbdc2\u0026#34; meta-oe meta-python meta-networking meta-multimedia meta-filesystems = \u0026#34;langdale:3f9340a9241d497753b330d90d6a3d8332c1ba7f\u0026#34; meta-raspberrypi = \u0026#34;langdale:6f5771d2bcfbfb8f8ce17b455c29a5703f2027c9\u0026#34; Initialising tasks: 100% |#######################################| Time: 0:00:03 Sstate summary: Wanted 0 Local 0 Mirrors 0 Missed 0 Current 2106 (0% match, 100% complete) NOTE: Executing Tasks Prepare the built image to the SDCard. I use the GParted to format the SD Card to support the ext3 file system.\n$ sudo bmaptool copy --bmap core-image-minimal-raspberrypi4-64-20210706094018.rootfs.wic.bmap core-image-minimal-raspberrypi4-64-20210706094018.rootfs.wic.bz2 /dev/mmcblk0 [sudo] password for hlkn: bmaptool: info: block map format version 2.0 bmaptool: info: 148583 blocks of size 4096 (580.4 MiB), mapped 85941 blocks (335.7 MiB or 57.8%) bmaptool: info: copying image \u0026#39;core-image-minimal-raspberrypi4-64-20210706094018.rootfs.wic.bz2\u0026#39; to block device \u0026#39;/dev/mmcblk0\u0026#39; using bmap file \u0026#39;core-image-minimal-raspberrypi4-64-20210706094018.rootfs.wic.bmap\u0026#39; bmaptool: info: 100% copied bmaptool: info: synchronizing \u0026#39;/dev/mmcblk0\u0026#39; bmaptool: info: copying time: 19.0s, copying speed 17.6 MiB/sec Rasberry PI with Docker project # Notes to configure, build and run Docker in the raspberry-pi\n$ mkdir -p ~/projects/rpid/source $ cd ~/projects/rpid/source $ git clone git://git.yoctoproject.org/poky $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-openembeded $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-rapberrypi $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-virtualization $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-security $ git branch --all $ git checkout langdale $ git clone git://git.yoctoproject.org/meta-selinux $ git branch --all $ git checkout langdale or cd /workdir # sudo chown -R build:build * git clone -b langdale --depth=1 git://git.yoctoproject.org/poky.git git clone -b langdale --depth=1 git://git.yoctoproject.org/meta-raspberrypi.git git clone -b langdale --depth=1 git://git.yoctoproject.org/meta-virtualization.git git clone -b langdale --depth=1 git://git.yoctoproject.org/meta-security.git git clone -b langdale --depth=1 git://git.yoctoproject.org/meta-selinux.git git clone -b langdale --depth=1 git://git.openembedded.org/meta-openembedded.git source poky/oe-init-build-env bitbake-layers add-layer ../meta-openembedded/meta-oe bitbake-layers add-layer ../meta-openembedded/meta-python bitbake-layers add-layer ../meta-openembedded/meta-multimedia bitbake-layers add-layer ../meta-openembedded/meta-networking bitbake-layers add-layer ../meta-openembedded/meta-perl bitbake-layers add-layer ../meta-openembedded/meta-filesystems bitbake-layers add-layer ../meta-virtualization bitbake-layers add-layer ../meta-selinux bitbake-layers add-layer ../meta-security bitbake-layers add-layer ../meta-raspberrypi bitbake-layers show-layers Option 1: Configure the local.conf and bblayers.conf the raspberrypi with docker support\n$ vi conf/local.conf # This sets the default machine to be qemux86-64 if no other machine is selected: MACHINE ??= \u0026#34;raspberrypi4-64\u0026#34; #MACHINE ??= \u0026#34;qemux86-64\u0026#34; # CONF_VERSION is increased each time build/conf/ changes incompatibly and is used to # track the version of this file when it was generated. This can safely be ignored if # this doesn\u0026#39;t mean anything to you. CONF_VERSION = \u0026#34;1\u0026#34; DISTRO_FEATURES_append = \u0026#34; virtualization\u0026#34; DISTRO_FEATURES_append = \u0026#34; systemd\u0026#34; VIRTUAL-RUNTIME_init_manager = \u0026#34;systemd\u0026#34; DISTRO_FEATURES_BACKFILL_CONSIDERED = \u0026#34;sysvinit\u0026#34; VIRTUAL-RUNTIME_initscripts = \u0026#34;systemd-compat-units\u0026#34; IMAGE_INSTALL_append = \u0026#34; sysstat\u0026#34; IMAGE_INSTALL_append = \u0026#34; cronie\u0026#34; IMAGE_INSTALL_append = \u0026#34; openssh\u0026#34; IMAGE_INSTALL_append = \u0026#34; openssh-sftp\u0026#34; IMAGE_INSTALL_append = \u0026#34; openssh-sftp-server\u0026#34; IMAGE_INSTALL_append = \u0026#34; curl-dev\u0026#34; IMAGE_INSTALL_append = \u0026#34; docker-ce\u0026#34; IMAGE_INSTALL_append = \u0026#34; libstdc++\u0026#34; $ vi conf/bblayers.conf # POKY_BBLAYERS_CONF_VERSION is increased each time build/conf/bblayers.conf # changes incompatibly POKY_BBLAYERS_CONF_VERSION = \u0026#34;2\u0026#34; BBPATH = \u0026#34;${TOPDIR}\u0026#34; BBFILES ?= \u0026#34;\u0026#34; BBLAYERS ?= \u0026#34; \\ /home/hlkn/rpi-gategarth/layers/poky/meta \\ /home/hlkn/rpi-gategarth/layers/poky/meta-poky \\ /home/hlkn/rpi-gategarth/layers/poky/meta-yocto-bsp \\ /home/hlkn/rpi-gategarth/layers/meta-raspberrypi \\ /home/hlkn/rpi-gategarth/layers/meta-openembedded/meta-oe \\ /home/hlkn/rpi-gategarth/layers/meta-openembedded/meta-python \\ /home/hlkn/rpi-gategarth/layers/meta-openembedded/meta-networking \\ /home/hlkn/rpi-gategarth/layers/meta-openembedded/meta-filesystems \\ /home/hlkn/rpi-gategarth/layers/meta-virtualization \\ \u0026#34; Options 2: Follow the IBM tutorial 30 $ vi local.conf MACHINE ?= \u0026#34;raspberrypi4-64\u0026#34; ENABLE_UART = \u0026#34;1\u0026#34; ENABLE_I2C = \u0026#34;1\u0026#34; KERNEL_MODULE_AUTOLOAD:rpi += \u0026#34;i2c-dev i2c-bcm2708\u0026#34; # add a feature EXTRA_IMAGE_FEATURES:append = \u0026#34; debug-tweaks ssh-server-dropbear package-management tools-sdk\u0026#34; DISTRO_FEATURES:append = \u0026#34; bluez5 bluetooth wifi polkit acl xattr pam virtualization security systemd\u0026#34; DISTRO_FEATURES:remove = \u0026#34; sysvinit\u0026#34; VIRTUAL-RUNTIME_init_manager = \u0026#34;systemd\u0026#34; LICENSE_FLAGS_ACCEPTED = \u0026#34;synaptics-killswitch\u0026#34; # add a recipe CORE_IMAGE_EXTRA_INSTALL:append = \u0026#34; vim\u0026#34; DISTRO_FEATURES_BACKFILL_CONSIDERED = \u0026#34;\u0026#34; IMAGE_INSTALL:append = \u0026#34; ntpdate i2c-tools podman crun buildah skopeo cgroup-lite procps ca-certificates kernel-modules python3-pip python3-dbus ebtables cri-o cri-tools e2fsprogs-resize2fs linux-firmware-bcm43430 bluez5 python3-smbus wpa-supplicant bridge-utils git hostapd\u0026#34; IMAGE_ROOTFS_EXTRA_SPACE = \u0026#34;8097152\u0026#34; # BB_NUMBER_THREADS = \u0026#34;9\u0026#34; # PARALLEL_MAKE = \u0026#34;-j 9\u0026#34; INHERIT += \u0026#34;rm_work\u0026#34; Run the bitbake command to generate the image. The above features add a lot more components than we actually need for runing MicroShift. These were added to permit some development and experimentation for learning yocto with a generous 8GB disk size. The python3, pip3, vim, i2cdetect, podman and crun runtime are installed. The debug-tweaks allows us to login as root without password.\nbitbake rpi-test-image -n bitbake rpi-test-image --runonly=fetch bitbake rpi-test-image # This will take a couple of hours This produces the rpi-test-image-raspberrypi4-64.wic.bz2.The balenaEtcher that we use to write to MicroSDXC card does not understand the bz2 format built by bitbake, so we extract the image\ncd tmp/deploy/images/raspberrypi4-64 bzip2 -d -f rpi-test-image-raspberrypi4-64.wic.bz2 Run docker in raspberrypi using the Option-1 configuration\nroot@raspberrypi4-64:~# dokerd \u0026amp; root@raspberrypi4-64:~# ps -ef|grep dockerd 207 root 0:01 dockerd 334 root 0:00 grep dockerd $ ssh root@192.168.0.229 The authenticity of host \u0026#39;192.168.0.229 (192.168.0.229)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:R+OYjsNv6MhVBb+G5/fwQUcExcB9gSZ3IgOzTLlKT48. Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added \u0026#39;192.168.0.229\u0026#39; (ECDSA) to the list of known hosts. root@raspberrypi4-64:~# root@raspberrypi4-64:~# root@raspberrypi4-64:~# dockerd INFO[2023-03-29T10:08:02.537766772Z] Starting up INFO[2023-03-29T10:08:02.560111257Z] libcontainerd: started new containerd process pid=214 INFO[2023-03-29T10:08:02.560950036Z] parsed scheme: \u0026#34;unix\u0026#34; module=grpc-java INFO[2023-03-29T10:08:02.561491685Z] scheme \u0026#34;unix\u0026#34; not registered, fallback to default scheme module=grpc-java INFO[2023-03-29T10:08:02.562066204Z] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock 0 }] } module=grpc-java INFO[2023-03-29T10:08:02.562607260Z] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; module=grpc-java INFO[2023-03-29T10:08:03.637249883Z] starting containerd revision=409c87ba59dd96965239573aa9458a3585c05468.m version=v1.4.4-36-g409c87ba5.m INFO[2023-03-29T10:08:04.043501494Z] loading plugin \u0026#34;io.containerd.content.v1.content\u0026#34;… type=io.containerd.content.v1 INFO[2023-03-29T10:08:04.044683051Z] loading plugin \u0026#34;io.containerd.snapshotter.v1.aufs\u0026#34;… type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.050882372Z] skip loading plugin \u0026#34;io.containerd.snapshotter.v1.aufs\u0026#34;… error=\u0026#34;aufs is not supported (modprobe aufs failed: exit status 1 \\\u0026#34;modprobe: FATAL: Module aufs not found in directory /lib/modules/5.10.17-v8\\n\\\u0026#34;): skip plugin\u0026#34; type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.051224428Z] loading plugin \u0026#34;io.containerd.snapshotter.v1.devmapper\u0026#34;… type=io.containerd.snapshotter.v1 WARN[2023-03-29T10:08:04.051481576Z] failed to load plugin io.containerd.snapshotter.v1.devmapper error=\u0026#34;devmapper not configured\u0026#34; INFO[2023-03-29T10:08:04.051665225Z] loading plugin \u0026#34;io.containerd.snapshotter.v1.native\u0026#34;… type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.052578485Z] loading plugin \u0026#34;io.containerd.snapshotter.v1.overlayfs\u0026#34;… type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.054358746Z] loading plugin \u0026#34;io.containerd.snapshotter.v1.zfs\u0026#34;… type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.055782303Z] skip loading plugin \u0026#34;io.containerd.snapshotter.v1.zfs\u0026#34;… error=\u0026#34;path /var/lib/docker/containerd/daemon/io.containerd.snapshotter.v1.zfs must be a zfs filesystem to be used with the zfs snapshotter: skip plugin\u0026#34; type=io.containerd.snapshotter.v1 INFO[2023-03-29T10:08:04.056042507Z] loading plugin \u0026#34;io.containerd.metadata.v1.bolt\u0026#34;… type=io.containerd.metadata.v1 WARN[2023-03-29T10:08:04.056633211Z] could not use snapshotter devmapper in metadata plugin error=\u0026#34;devmapper not configured\u0026#34; INFO[2023-03-29T10:08:04.056818008Z] metadata content store policy set policy=shared INFO[2023-03-29T10:08:04.078754400Z] loading plugin \u0026#34;io.containerd.differ.v1.walking\u0026#34;… type=io.containerd.differ.v1 INFO[2023-03-29T10:08:04.079083456Z] loading plugin \u0026#34;io.containerd.gc.v1.scheduler\u0026#34;… type=io.containerd.gc.v1 INFO[2023-03-29T10:08:04.079435549Z] loading plugin \u0026#34;io.containerd.service.v1.introspection-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.079831623Z] loading plugin \u0026#34;io.containerd.service.v1.containers-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.080098512Z] loading plugin \u0026#34;io.containerd.service.v1.content-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.080321012Z] loading plugin \u0026#34;io.containerd.service.v1.diff-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.080667809Z] loading plugin \u0026#34;io.containerd.service.v1.images-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.080903606Z] loading plugin \u0026#34;io.containerd.service.v1.leases-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.081136569Z] loading plugin \u0026#34;io.containerd.service.v1.namespaces-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.081352513Z] loading plugin \u0026#34;io.containerd.service.v1.snapshots-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.081569884Z] loading plugin \u0026#34;io.containerd.runtime.v1.linux\u0026#34;… type=io.containerd.runtime.v1 INFO[2023-03-29T10:08:04.082805311Z] loading plugin \u0026#34;io.containerd.runtime.v2.task\u0026#34;… type=io.containerd.runtime.v2 INFO[2023-03-29T10:08:04.083777590Z] loading plugin \u0026#34;io.containerd.monitor.v1.cgroups\u0026#34;… type=io.containerd.monitor.v1 INFO[2023-03-29T10:08:04.090603300Z] loading plugin \u0026#34;io.containerd.service.v1.tasks-service\u0026#34;… type=io.containerd.service.v1 INFO[2023-03-29T10:08:04.091025856Z] loading plugin \u0026#34;io.containerd.internal.v1.restart\u0026#34;… type=io.containerd.internal.v1 INFO[2023-03-29T10:08:04.093178396Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.containers\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.093511174Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.content\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.093740433Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.diff\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.093958878Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.events\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.094174582Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.healthcheck\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.094391082Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.images\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.094599675Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.leases\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.094809749Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.namespaces\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.095029990Z] loading plugin \u0026#34;io.containerd.internal.v1.opt\u0026#34;… type=io.containerd.internal.v1 INFO[2023-03-29T10:08:04.097362326Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.snapshots\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.097741289Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.tasks\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.097978419Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.version\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.098192604Z] loading plugin \u0026#34;io.containerd.grpc-java.v1.introspection\u0026#34;… type=io.containerd.grpc-java.v1 INFO[2023-03-29T10:08:04.100055884Z] serving… address=/var/run/docker/containerd/containerd-debug.sock INFO[2023-03-29T10:08:04.100629755Z] serving… address=/var/run/docker/containerd/containerd.sock.ttrpc INFO[2023-03-29T10:08:04.101130218Z] serving… address=/var/run/docker/containerd/containerd.sock INFO[2023-03-29T10:08:04.101361459Z] containerd successfully booted in 0.479344s INFO[2023-03-29T10:08:04.174947773Z] parsed scheme: \u0026#34;unix\u0026#34; module=grpc-java INFO[2023-03-29T10:08:04.175125958Z] scheme \u0026#34;unix\u0026#34; not registered, fallback to default scheme module=grpc-java INFO[2023-03-29T10:08:04.175262977Z] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock 0 }] } module=grpc-java INFO[2023-03-29T10:08:04.175364273Z] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; module=grpc-java INFO[2023-03-29T10:08:04.180830205Z] parsed scheme: \u0026#34;unix\u0026#34; module=grpc-java INFO[2023-03-29T10:08:04.180963853Z] scheme \u0026#34;unix\u0026#34; not registered, fallback to default scheme module=grpc-java INFO[2023-03-29T10:08:04.181161427Z] ccResolverWrapper: sending update to cc: {[{unix:///var/run/docker/containerd/containerd.sock 0 }] } module=grpc-java INFO[2023-03-29T10:08:04.181242575Z] ClientConn switching balancer to \u0026#34;pick_first\u0026#34; module=grpc-java ERRO[2023-03-29T10:08:04.187997490Z] Failed to built-in GetDriver graph btrfs /var/lib/docker ERRO[2023-03-29T10:08:04.196119461Z] failed to mount overlay: no such device storage-driver=overlay2 ERRO[2023-03-29T10:08:04.201334206Z] AUFS was not found in /proc/filesystems storage-driver=aufs ERRO[2023-03-29T10:08:04.208779381Z] failed to mount overlay: no such device storage-driver=overlay ERRO[2023-03-29T10:08:04.208921825Z] Failed to built-in GetDriver graph devicemapper /var/lib/docker WARN[2023-03-29T10:08:04.341482234Z] Your kernel does not support cgroup memory limit WARN[2023-03-29T10:08:04.341604105Z] Your kernel does not support cgroup rt period WARN[2023-03-29T10:08:04.341664994Z] Your kernel does not support cgroup rt runtime WARN[2023-03-29T10:08:04.341748161Z] Your kernel does not support cgroup blkio weight WARN[2023-03-29T10:08:04.341810383Z] Your kernel does not support cgroup blkio weight_device INFO[2023-03-29T10:08:04.343829385Z] Loading containers: start. WARN[2023-03-29T10:08:04.371513875Z] Running modprobe bridge br_netfilter failed with message: modprobe: WARNING: Module br_netfilter not found in directory /lib/modules/5.10.17-v8 insmod /lib/modules/5.10.17-v8/kernel/net/llc/llc.ko insmod /lib/modules/5.10.17-v8/kernel/net/802/stp.ko insmod /lib/modules/5.10.17-v8/kernel/net/bridge/bridge.ko , error: exit status 1 INFO[2023-03-29T10:08:05.046749137Z] Default bridge (docker0) is assigned with an IP address 172.17.0.0/16. Daemon option --bip can be used to set a preferred IP address INFO[2023-03-29T10:08:05.541597770Z] Loading containers: done. INFO[2023-03-29T10:08:05.823780138Z] Docker daemon commit=ff3fbc9d55de9fce497cd058411f21f4a4dcdb7c graphdriver(s)=vfs version=v19.03.13-ce INFO[2023-03-29T10:08:05.824912251Z] Daemon has completed initialization INFO[2023-03-29T10:08:05.935543915Z] API listen on /var/run/docker.sock $ docker login --username henrynguyen --password $ sudo docker run hello-world Unable to find image \u0026#39;hello-world:latest\u0026#39; locally latest: Pulling from library/hello-world 7050e35b49f5: Pull complete Digest: sha256:ffb13da98453e0f04d33a6eee5bb8e46ee50d08ebe17735fc0779d0349e889e9 Status: Downloaded newer image for hello-world:latest ERRO[2023-03-29T10:09:22.228694279Z] 57c0bda5e06d9e1c30d9ab6c6b4f76f38606723e5b76b64885cc98b8260f7ba9 cleanup: failed to delete container from containerd: no such container ERRO[2023-03-29T10:09:22.229116046Z] Handler for POST /v1.40/containers/57c0bda5e06d9e1c30d9ab6c6b4f76f38606723e5b76b64885cc98b8260f7ba9/start returned error: failed to create endpoint sad_cohen on network bridge: failed to add the host (veth03ee259) \u0026lt;=\u0026gt; sandbox (vethabd8cd3) pair interfaces: operation not supported docker: Error response from daemon: failed to create endpoint sad_cohen on network bridge: failed to add the host (veth03ee259) \u0026lt;=\u0026gt; sandbox (vethabd8cd3) pair interfaces: operation not supported. ERRO[0005] error waiting for container: context canceled root@raspberrypi4-64:~# docker container ls -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 57c0bda5e06d hello-world \u0026#34;/hello\u0026#34; 10 seconds ago Created sad_cohen root@raspberrypi4-64:~# docker image ls -a REPOSITORY TAG IMAGE ID CREATED SIZE hello-world latest 46331d942d63 12 months ago 9.14kB "},{"id":22,"href":"/homelab/bitbucket/bitbucket/","title":"Bitbucket","section":"Homelabs","content":""},{"id":23,"href":"/homelab/dns/dns/","title":"Dns","section":"Homelabs","content":""},{"id":24,"href":"/homelab/gitslaberver/gitlabserver/","title":"Gitlabserver","section":"Homelabs","content":""},{"id":25,"href":"/homelab/gitserver/gitserver/","title":"Gitserver","section":"Homelabs","content":""},{"id":26,"href":"/homelab/homelab/","title":"Homelab","section":"Homelabs","content":""},{"id":27,"href":"/posts/homelab-skill/","title":"Homelab Skill (draft)","section":"Blog","content":" [My Home Lab] # We setup the Development Environment for homelab.\nOn the internet facing we allow for the following traffic to transport to and from internet:\nMail - POP/POPS, IMAP/IMAPS, SMTP/SMTPS Leshan - Bootstrap and Device Management Web - HTTP/HTTPS Bastion Host - SSH/SFTP Github via SSH and HTTPS Next Cloud -TBD Code Control Service\nGit Server GitLab Server Bitbuck Server JIRA Server DNS Service\nBind9 Mail Service\nMailserver using the mailcow docker Web Service\nWe use Hugo to develop the web service Study # Training courses that we have studied and learned in the Github, Linkedin, Udemy, and Youtube;\nYoutube # Bind9 Docker - Real DNS at home Simple Git Server - using RasberryPi GitLb Server using RaspberryPi4 Docker Network is CRAZY!! Docker Networking Tutorial\nLinkedin # Docker for Java Developers by Arun Gupta Completed - Out of Date Kubernetes for Java Developers by Arun Gupta 60 % On Progressed\nUdemy # Docker - Hands on for Java Developers\nThe objective of the study is to\nSet up the tool set used for the homelab used for the Development, Deployment, Production. Development Tools # We use\nFor IDE we select to use the Jetbrains suite to develop PoC and Application in GoLand for Golang WebStorm for NodeJS, NPM and Javascript CLion for C/C++ IntelliJ for Java Pycharm for Python DataGrip for Database Access to MySQL, Postgresql, DynamoDB etc\u0026hellip; TeamCity for CI/CD Docker Kubernetes Database Mailserver - Mailcow running as a Docker Development Environment # For Code Management, we use the following set-ups\nGit Server running on a RaspberryPi4/4G and ubuntu 22.10 server GitLab Server running on a RapberryPi4/8G and ubuntu 22.10 server I also run GitHub used to share the findings to the community For DNS, we run bind9 docker and configure all server(s) resolv.conf to use the DNS Name Server "},{"id":28,"href":"/homelab/","title":"Homelabs","section":"","content":""},{"id":29,"href":"/homelab/jira/jira/","title":"Jira","section":"Homelabs","content":""},{"id":30,"href":"/homelab/mailserver/mailserver/","title":"Mailserver","section":"Homelabs","content":""},{"id":31,"href":"/homelab/nextcloud/nextcloud/","title":"Nextcloud","section":"Homelabs","content":""},{"id":32,"href":"/homelab/website/website/","title":"Website","section":"Homelabs","content":""},{"id":33,"href":"/posts/hugo-skill/","title":"Hugo Skill (draft)","section":"Blog","content":" Study # Training courses that I have studied and learned in the Github, Linkedin, Udemy, and Youtube; I also setup the Development Environment for hugo.\nThe objective of the study is to\nSet up the tool set used for the hugo Development Set up the tool set used to maintain, operate and administer my website and other projects Set up the development environment to use docker and kubernetes whenever possible thus allowing an integration from Development, Testing, Pre-Production and Production. Development Tools # I use\nJetbrains GoLand/WebStorm for my Integrated Development Environment. I also test out the development using Visual Code. Docker Desktop to maintain and monitor the Web and DB dockers certbot to manage free ssl certificate nginx docker running HTTP and HTTPS Development Environment # Refer to HomeLab/Code Management\n"},{"id":34,"href":"/posts/golang-skill/","title":"Golang Skill (draft)","section":"Blog","content":" GitHub Referece\nDevelopment Environment # The Golang Development Environment is setup as follows:\nWe use GoLand as the primary Integrated Development Environment tool.\nGoLand with Git Servers: to connect to Git Server,GitLab Server, Bitbucket and Github GoLand with Git: to manage Code Control - Local and Remote Git activities. GoLand Debug: to debug and learn everything about Golang GoLand Remote Debug: to remote debug to diagnose code issues and defects in the integration GoLand and Docker Desktop as an Integrated Development Environment: to create the development environment using Docker and Kubernetes e.g. Kafka, Database, JBoss, Web servers (Apache, nginx, jetty) We use TeamCity or Jenkins to perform CI/CD We use HttpClient plugin comes with GoLand for Restful Integrated Testing Docker Desktop: We use Docker Desktop to deploy various environments used for the development and the integration testing: Kafka dockers referring to the diagram for the Docker Desktop containing various Kafka sources provided by Confluent docker, Redpanda C++ Kafka and Redpanda Data Github Debezium Docker etc\u0026hellip; Kubernetes The reasons for composing the docker services and/or kubernetes pods are:\nWe allow each Developer to replicate the Development Environment with docker, thus suitable for microservice team and work breakdown We deploy the application in the Development Environment to the application in the Testing Environment with docker We deploy the application with CI/CD in mind and automate testing When we learn a new computer language, the debug will assist the learning. We setup two approaches to debug Golang: We use the GoLand IDE debug the code When the Developers work with the Testers to trace any issues We use the GoLand or Visual Code IDE to perform the remote debug to a Golang process Study # Refer to Golang Study for detailed information Refer to Kafka Study for detailed information Development Tools # Refer to Developement Tools to see how use the GoLand and Docker Desktop "},{"id":35,"href":"/posts/3-holy-trinities/","title":"3 Holy Trinities (draft)","section":"Blog","content":"The term “three holy trinities” can refer to different concepts depending on the context. One possible meaning is the Christian doctrine of the Trinity, which is the belief that God is one being in three persons: Father, Son, and Holy Spirit. My software development doctrine is based on the “three holy trinities” of Architecture, Data to Information Modelling, and Methodology.\nArchitecture defines how all components interact through well-defined protocols. Data to Information Modelling describes the data or information used or produced by the components. Methodology determines the tools, environments, techniques, and processes for developing various applications within the components. By studying the history of these technologies, we can gain more insight into the doctrine of the “three holy trinities” in software development. Architecture # TMN \u0026amp; CCiTT # SNMP \u0026amp; IETF # CoAP/LwM2M/IPSO \u0026amp; OMA # Any Architectures with Business Logic to be implemented using Finite State Machine # Event Driven Architecture # Monolithic Architecture # Domain Driven Architecture # Hexagon Driven Architecture # Data and Business Logic Modelling # TMN \u0026amp; CCiTT with M3xxxx-MIB # SNMP \u0026amp; IETF with RFC-MIB # OMA with IPSO for LwM2M and IPSO for Business Logic # Methodology # Process # Development Environment \u0026amp; Tools # DevOps Environment \u0026amp; Tools # CICD Tools # "},{"id":36,"href":"/posts/home/","title":"Home (draft)","section":"Blog","content":"Here are the summary of the solution and standards for CoAP, LwM2M and IPSO:\nSolution \u0026amp; Standard to Support CoAP # Device and Protocol to work in a constraint environment – CoAP Constraint of Application Protocol\nProtocol operates s constraint resources, e.g. Power devices run using battery or Transmit data in an Intermittent and narrow band. CoAP protocol is a Restful-like API with Restful response code Operate in various protocol stacks, UDP/DTLS, TCP/TLS and Websocket, SMS and MQTT Message encodes/decoded and transported between devices using CBOR Concise Binary Object, Text, TLV, JSON Solution and Standard to support LwM2M # Device Communication with its Management System – LwM2M Light Weight Machine to Machine Protocol – engineered on the “wisdom” of machine to machine interface\nDevice authentication with Bootstrap without Security and with Security PSK, RSK, X500 Self-Signed and X500 Certificate Device authorisation with Registration and regular Registration Update Device maintenance Firmware/Software Upgrade Device configuration with Device Management and Service Enablement with Read, Read/Write, Execute Solution \u0026amp; Standard to support Data/Business Logic Modelling # Device Resource/Data Model with IPSO Internet Protocol Smart Object OMA Open Mobile Alliance provide a registration framework to allow all industry sectors, Energy, Telco, Mobile and Internet\nTo perform Data/Information Model using Device Management/Service Enablement and Report Notification Hypotheses into Use Cases # For IoT Application Domain: IoT Use Case (Firmware Application) # Digital Meters of Water, Power, Gas, Electricity (measurement data), Automotive (measurement with CAN bus, Tracking with GPS) Cargo container tracking on land, on sea, and in the air We hypothesize on a solution to develop Firmware Application running in the e.g. Arm Core ( CPUs A-Core or M-Core For Mobile Application Domain: Mobile Use Case (Mobile Application) # Banking, Stock Market domains (leverage on the authentication with security enabling and report notification in real time to inform user) We hypothesize on a solution to develop Mobile Application running Mobile devices e.g. Android/Apple phones and tablets "},{"id":37,"href":"/about/","title":"Profile","section":"","content":"Please note that I am in the process to consolidate my study, working knowledge and/or wisdom into my blog as at last 3 decades I have rushed from company to another and from one project to another to deliver the outcomes.\nIt might take some time for me to complete the blog with old and new articles.\nThank you for visiting my blog and your understanding.\nPersonal Details # Website: https://theitservice.com.au/henrynguyen\nEmail: henrynguyen@theitservice.com.au and cc to henrylknguyen@outlook.com\nPhone: 0425782332\nEducation # 1983-1986: Electrical Engineering Bachelor Degree major in Computer Science and Computer Control with Honour at the University of Melbourne 1987-1991: Master Degree major in Artificial Intelligence and Expert System used to train the Telephone Traffic Congestion with Safer Routes in Communication Systems and Networks at University of Technology Profile Summary # Referring to Projects and PoC for further information\nCGI/Unico (2-years Fulltime) Techtonica (1-year Contract) Extel Technologies (3-years Contract) I return back to work in the Research \u0026amp; Development from 2016 until now. I was responsible\nto develop Cloud solution using MQTT/AWS Services and CoAP/LwM2M/IPSO and to develop PoC for Defence solution using DDS using the Embedded Linux Yocto/OpenEmbedded and Docker. to develop the Modini - Mobile Assurance System extending the support for 3G/4G to 5G at CGI Telstra (3-years Contract-\u0026gt;Fulltime) ANZ (4years Contract) Australia Post (3-years Contract) My next 10-12 years from 2004 to 2015 I worked in the System Integrator and IT infrastructure. I was responsible\nto deploy Telstra Titan Transformation programs and solutions for Home Gateway, Fibre to the Node (GPON), Voice Over IP (GenView/GenBand) and Metropolitan Ethernet Forum (MEF). to work as Unix Technical Consultant at ANZ Bank where I racked/stacked Enterprise Unix and Linux, build OS with Jumpstart and Private Cloud, and perform Disaster Recovery before transitioning to the Operation teams to work as an Infrastructure Design and Architect at Australia Post for a various Digital projects and Parcel Transformation program including planning, designing, and building parcel data centre together with integrating to the AusPost IT solution. Telecom Australia (5-years Fulltime) Nokia (4-years Fulltine) NEC (1-year Contract) Ericsson Australia (3-years Contract) Extel Technologies (4 years Contract-\u0026gt;Fulltime) My first 10-15 years from 1987 to 2004 I worked as a Graduate Software Engineer to Principal Engineer. I was responsible\nto develop the Telco Element Management Systems for ISDN-BA using TMN-Q3 Short Stack, to develop the integrated software application for Telecom Australia application for IEEE 802.6 Metropolitan LAN using SNMP, AXE Switches together with Interception Management using RPC and develop the Element Management System ADSL/ADSL2/ADSL2+ Tributary Access Network/SHDSL Repeaters/ATM \u0026amp; ATM-IMA \u0026amp; IP Backhaul using SNMPv1/v2, Java, J2EE, Struts. Skills # Software Engineer Skill # Java Skill / Java Projects C/CPP Skill / C/CPP Projects Android Skill / Android Projects Yocto Skill / Yocto Research and PoC Full Stack(FrontEnd (JSF/JSP/Sencha-ExtJS/Javascript/VueJS) BackEnd (JBoss EAP 6 and 7/ Tomcat / Jetty/ Restful with Java/JAXRS/ Restful with C++) Temporal Skill Architecture/Tempoeralite or Server/API with Protobuf and gRPC Service/Java-SDJ/GoSDK Golang Skill Kafka Skill Infrastructure Engineer Skill # Homelab Skill(DNS Bind9/Web Site Apacher/nginx/Mail Server with Mailcow/Git Server/GitLab Server/JIRA) Docker Skill Kubernetes AWS DevOps and Software Engineer Skill # Computing (EC2/LB) with Storage/Zone/VPN/Network/Route 53 consideration Storage with DynamoDB/RDS/S3 IoT Device Gateway with Cognito/MQTT/Policy/Rule/Serverless AWS IAM AWS Metrics and Monitor Software Engineer Projects # Modini - Java-7 \u0026amp; J2EE: is an application developed by Unico/CGI to support Telstra Mobile Service Assurance for 3G/4G/4G-5G. The application has been deployed and supported since 1990-now to support 3G/4G. The application was developed using 10-15 years old technologies. the Front End technologies using Java Server Face (JSF), Javascript, Groovy, the Back End technologies using EJB/JBoss EAP 6.3 and the Interface technologies with Telstra Operation Support Systems using SOAP/WSDL, XML/XSD, CLI, JMS and the Persistent Storage technologies using MySQLTelstra the application is developed using Java 7 and Gradle v2 I worked a Senior Java Developer and was responsible to work with the System Architect to plan the requirements into Agile Sprint and the Integration Tester, System Support Engineer and Production Support Engineer. To extend the current application architecture to support 3G/4G versions and enhance 4G-5G/5G-GA with both backward and forward software releases and compatibility To develop four major releases to Telstra without any patch releases To develop software using JIRA for planning the sprint (features, releases and defects), Git/Bitbucket for code control, Jenkins for CICD To fix critical defects such as restarting due to running out of system resources Android BANTAM - Android-SDK and Java-8: is an Android application used to manage battery and all Military device connecting to the USB. The application was developed using Android SDK and Java 8 and running as the Android v10. The USB is mostly engineered and developed to with serial specification with RS232. The USB application is developed to run at raw speed 10Gbps for USB TypeC interface or 40Gbps for USB Thunderbolt 4 interface. The research and development requires the Android OS and hardware interface. Yocto and Linux Embedded PoC - Embedded Linux and C/C++ is a Proof of Concept on how to develop the Linux Embedded Software South East Water program South East Water Digital Meter Java-8/Java-11 \u0026amp; redis Local Terminal Android-SDK and Java8 IPSO Conformance Testing Leshan/Java-8 \u0026amp; Cucumber Enhanced Leshan Bootstrap and Device Management Leshan and Java-8 or Java-11 IoT Sleeping project IoT Sensor Tracking System project IoT Tracking Device Project Element Managment System for ADSL Infrastructure Engineer Projects # Infrastructure Projects at ANZ Infrastructure Projects at Australia Post Research/Proof Of Concept # Temporal Workflow Kafka and Event Management System resarch and develop a Proof of Concept using Kafka, Java and Golang running on the Microservice Event Management architecture Deploy Kafka version 3.xx zookeeper, kafka cluster, kafka drop running in docker and/or kubernetes pods desktop Producer and Consumer microservice applications developed using Java-17 SpringBoot-3.0.1 Producer and Consumer microservice applications developed using Go 1.19.x-1.20.x Development Infrastructure Mailserver register theitservice.com.au domain name/subdomain name using AWS DNS/Hostedzone Services and AWS DKIM together with running the mailcow docker locally to maintain DNS running bind9 docker the homelab subdomain to support docker swarm and kubernetes together with local servers Website running the apache/nginx docker to perform the realtime update of the theitservice website using hugo and running letsencrypt to refresh the SSL certificate Docker and Kubernetes Code Control Local/Remote code control with Gitserver, Gitlabserver, Bitbucket and Remote code control with Github Jetbrains Development Tool with Code Control Visual Code and Eclipse Development with Code Control Feel free to reach out and hire me for you next project. # "}]